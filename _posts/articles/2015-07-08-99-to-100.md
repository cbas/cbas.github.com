---
title: How many numbers are there from 99 and 100?
abstract: Exploration of the IEEE 754 floating-point numbers.
published: true
comments: true
author_email: seb@ninja.sg
author: Sebastiaan Deckers
layout: article
categories:
- articles
---
## Prologue
*Pick a number from 1 to 100.*

Got one?

*Now pick a number from 99 to 100.*

Wait, what...

Chances are you first picked an integer and then felt confused at my illogical question. JavaScript, being superior to most humans, feels no such confusion. This leads me to a completely unimportant question: **How many numbers can JavaScript guess from 99 and 100?**

## Integer
Computers can represent an integer (i.e. wholesome, clean numbers like 1 or 5 or even 6843) as a sequence of bits. Since each bit can only be either 0 or 1, a sequence of length *n* bits can represent *2^n* unique values.

## Floating Point
Computers store real numbers (i.e. 1.5 or 621.43012) as their significant digits (the "significand") and a scale made up of a *base* and *exponent*.

### Significand
The significand is the sequence of digits without decimal point nor commas. This is an integer which can be stored as sequences of bits.

In decimal notation, these numbers have the same significand of *15*:

    15,000
    1.5
    15
    0.15
    0.000,000,015

### Scale
The scale is the position of the decimal point. By *floating* the scale a much larger range of numbers can be represented than if each binary value represented a unique number.

Here is what happens when we float the decimal point all the way from the first to last position of our significand:

    0.123
    1.23
    12.3
    123

As a shortcut the scale can be stored as the exponent of an agreed-upon base, commonly 2 or 10 or 16.

## Why aren't there infinite numbers?
In mathematics there may be infinite numbers, but our ability to record them in computer memory is limited.

The length of a binary sequence limits unique integers. Both the scale and significand in a floating point number are recorded as integers. An additional bit is used to indicate positive or negative. Therefore there is a limit to the precision in a floating point number -- in other words it is an approximation.

Floating point numbers are limited: Incredibly huge numbers or numbers that are very close to each other can not be told apart by computers. It would take too many bits to record their significand and scale with enough precision.

A floating point number is also a compromise between accuracy and range. More bits for the scale would allow a larger range, but at the cost of precision. And vice versa.

## JavaScript and Numbers
JavaScript represents numbers in the binary64 "double" format of the IEEE 754 Floating-Point specification.

The 64 bits are assigned as follows: 1 bit for the sign, 11 bits for the scale, and the remaining 52 bits for the significand.

![Bits of an IEEE 754 number](http://i.imgur.com/dYIh8QV.png)

## 99 to 100
Back to our silly question.

The number 99 in JavaScript is stored as 64 + 32 + 2 + 1. This requires a binary floating point of 6 and is encoded as follows.

![Bits of the number 99](http://i.imgur.com/WHD0JbN.png)

This shows that the first bit is used for the positive sign (as opposed to *-99*). The 11 bits of the exponent represent a floating point position of 6. The first 6 bits of the significant are used to describe the integer 99.

That leaves the remaining 26 bits after the floating point to describe fractions from 99 and 100.

So in total there are **2^26** or **70,368,744,177,664** numbers from 99 and 100 (including 99 itself).

## Trivia
There are 23 chromosomes in humans, or 46 per couple. This means, given enough time and stamina, a single couple could produce as many genetically unique offspring as there are numbers from 99 to 100 in JavaScript.

## Notes
The exact rules of the IEEE 754 encoding scheme are slightly more complex than described above, but the differences irrelevant to the question.

Apologies for any off-by-one mistakes.
